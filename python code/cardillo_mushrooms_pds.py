# -*- coding: utf-8 -*-
"""Cardillo_Mushrooms_PDS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1McKvesX_9kRkUBUwjcW2AulXlOWt0dtc

# Executive Summary

**Problem:** Friendly Dog Park has a mushroom overgrowth problem. They need a method for park staff to classify any poisonous mushrooms for removal. While about only 1% of mushroom species are toxic, mushroom poisoning in dogs can cause symptoms like vomiting, kidney failure and even result in death. Treatment must be prompt, and veterinary visits can be expensive.  

**Solution:** Use a classification model to predict the edibility of mushrooms based on various physical characteristics. With this model as a guide, park staff can inspect the grounds daily prior to park opening and remove any potentially poisonous mushrooms. Guides can also be posted on billboards for park guests to reference and follow.

# Data Import and Pre-Processing
"""

!pip3 install -U ucimlrepo

'''Imported directly from documentation'''
from ucimlrepo import fetch_ucirepo

# fetch dataset
mushroom = fetch_ucirepo(id=73)

# data (as pandas dataframes)
X = mushroom.data.features
y = mushroom.data.targets

# metadata
#print(mushroom.metadata)

# variable information
#print(mushroom.variables)

X.info()

y.head()

X.head()

import pandas as pd

# combine X and Y for easier cleaning
data = pd.concat([X,y], axis=1)
data.info()

tab = pd.crosstab(data['stalk-root'],data['poisonous'])
print(tab)
data['stalk-root'].unique()

data.fillna({'stalk-root':'b'},inplace=True)
data.info()

tab = pd.crosstab(data['stalk-root'],data['poisonous'])
print(tab)
data['stalk-root'].unique()

"""Dropped N/A values from the dataframe.


"""

data.drop_duplicates(inplace=True)
data.info()

"""There were no duplicate values in our dataset.

# Exploratory Data Analysis
"""

import seaborn as sns
import matplotlib.pyplot as plt

# create a count plot of poisonous or edible mushrooms
target_labels = {'p':'Poisonous','e':'Edible'}
data['poisonous'] = data['poisonous'].map(target_labels)
print(data['poisonous'])

sns.countplot(data=data, x='poisonous',palette='colorblind')
plt.title('Distribution of Poisonous vs. Edible Mushrooms')
plt.xlabel('Edibility')
plt.ylabel('Count')
plt.show()

#create a cross tabulation table of target variable vs. bruise presence
cross_tab = pd.crosstab(data['bruises'],data['poisonous'])
cross_tab.rename(index={'f':'No','t':'Yes'},inplace=True)
print(cross_tab)

sns.heatmap(cross_tab,cmap="YlGnBu", fmt='g',annot=True)
plt.title('Distribution of Edibility vs. Bruise Presence')
plt.xlabel('Edibility')
plt.ylabel('Has Bruises?')

#create a cross tabulation table of target variable vs. bruise presence
cross_tab_shape = pd.crosstab(data['cap-shape'],data['poisonous'])
#cross_tab_shape.index = cross_tab_shape.index.map({'b':'Bell','c':'Conical','x':'Convex','f':'Flat','k':'Knobbed','s':'Sunken'})
cross_tab_shape.rename(index={'b':'Bell','c':'Conical','x':'Convex','f':'Flat','k':'Knobbed','s':'Sunken'}, columns={'0': 'edible','1':'poisonous'},inplace=True)
print(cross_tab_shape)

'''
Encoded Value: 0 -> Label: bell
Encoded Value: 1 -> Label: conical
Encoded Value: 2 -> Label: convex
Encoded Value: 3 -> Label: flat
Encoded Value: 4 -> Label: knobbed
Encoded Value: 5 -> Label: sunken
'''

# create a cross tab heatmap of target vs cap shape
sns.heatmap(cross_tab_shape,cmap="YlGnBu", fmt='g',annot=True)
plt.title('Distribution of Edibility vs. Cap Shape')
plt.xlabel('Edibility')
plt.ylabel('Cap Shape')

#create a cross tabulation table of target variable vs. bruise presence
cross_tab = pd.crosstab(data['cap-surface'],data['poisonous'])
cross_tab.rename(index={'f':'Fibrous','g':'Grooves','y':'Scaly','s':'Smooth'}, columns={'0': 'edible','1':'poisonous'},inplace=True)
print(cross_tab)

sns.heatmap(cross_tab,cmap="YlGnBu", fmt='g',annot=True)
plt.title('Distribution of Edibility vs. Cap Surface')
plt.xlabel('Edibility')
plt.ylabel('Cap Surface')

#create a cross tabulation table of ring type vs. edibility
cross_tab = pd.crosstab(data['ring-type'],data['poisonous'])
cross_tab.rename(index={'c':'Cobwebby','e':'Evanescent','f':'Flaring','l':'Large','n':'None','p':'Pendant','s':'Sheathing','z':'Zone'}, columns={'0': 'edible','1':'poisonous'},inplace=True)
print(cross_tab)

# cobwebby=c,evanescent=e,flaring=f,large=l, none=n,pendant=p,sheathing=s,zone=z

sns.heatmap(cross_tab,cmap="YlGnBu", fmt='g',annot=True)
plt.title('Distribution of Edibility vs. Ring Type')
plt.xlabel('Edibility')
plt.ylabel('Ring Type')

"""# Machine Learning Models"""

import matplotlib.pyplot as plt
import numpy as np

# encode categorical values to numerical
from sklearn.preprocessing import LabelEncoder

encoded_labels = {}

for column in data.columns:
  le = LabelEncoder()
  data[column] = le.fit_transform(data[column])
  encoded_labels[column] = le

#gives us a key so we know what number each label is encoded to
for column, le in encoded_labels.items():
    print(f"Feature Name: {column}")
    for encoded_value, label in enumerate(le.classes_):
      print(f"Encoded Value: {encoded_value} -> Label: {label}")
    print()

# separate into target and features for model
X = data.drop(columns='poisonous')
y = data['poisonous']

# perform feature selection
from sklearn.feature_selection import SelectKBest, chi2
from sklearn.model_selection import train_test_split

#select 10 of the most important features
select_features = SelectKBest(chi2, k=10)
selected = select_features.fit_transform(X,y)

feature_scores = select_features.scores_
feature_pvalues = select_features.pvalues_

feature_names = X.columns # get the chi2 and p values of all of the features

for name, score, pvalue in zip(feature_names,feature_scores,feature_pvalues):
  print(f"Feature Name: {name}, Chi2 Score: {score:.4f}, p-value: {pvalue:.4f}\n")

mask = select_features.get_support()
selected_features = X.columns[mask]
print(f'Based on the Chi 2 test, these show to be the most important features: {selected_features}')

# splits the data in to
X_train, X_temp, y_train, y_temp = train_test_split(selected,y,test_size=.2,random_state=42)
X_val,X_test,y_val,y_test = train_test_split(X_temp,y_temp,test_size=.5,random_state=42)

"""# Decision Tree Classifier"""

# import necessary modules
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
from sklearn.tree import DecisionTreeClassifier

# instantiate dt classifier
dt = DecisionTreeClassifier(max_depth=4,class_weight='balanced',random_state=42)

"""Without the use of the max_depth hyperparameter, the model overfits, with perfect accuracy. However, after tuning this hyperparameter, we see a model that generalizes and performs well overall."""

# fit the model on the training data, which will be validated
dt.fit(X_train,y_train)

# evaluate the model on the validation set
y_val_predictions = dt.predict(X_val)
val = accuracy_score(y_val,y_val_predictions)
print(val)

#getting the accuracy, recall, and f1 score to evaluate the model on the test set
y_test_predictions = dt.predict(X_test)
class_report = classification_report(y_test,y_test_predictions,output_dict=True)
print(class_report)

# create a heatmap of the classification report
report = pd.DataFrame(class_report).transpose()
report.rename(index={'0':'edible','1': 'poisonous'}, inplace=True)
sns.heatmap(report,annot=True,cbar=False, fmt='.2f')
plt.title('Classification Report Metrics')

#create a graph displaying the confusion matrix for the decision tree model

confusion = confusion_matrix(y_test,y_test_predictions)
total = confusion.sum() # get sum of test set observations
annot = [[f"{val}\n({val/total:.2%})" for val in row] for row in confusion] # format the annotations
sns.heatmap(confusion, annot=annot, fmt="",cmap='Blues')
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title('Decision Tree Confusion Matrix')
plt.xticks([0.5,1.5],['Negative','Positive'])
plt.yticks([0.5,1.5],['Negative','Positive'])

# import necessary modules for k folds cross validation
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score

#set the number of k folds, perform k fold cross validation
k = 10
kf = KFold(n_splits=k,shuffle=True,random_state=42)

# get the accuracy scores for k fold cross validation
k_fold_score = cross_val_score(dt,X_train,y_train, cv=kf,scoring='accuracy')
print("K Fold Accuracy\n" + str(k_fold_score) + "\n")
# f1 score
k_fold_score = cross_val_score(dt,X_train,y_train, cv=kf,scoring='f1')
print("K Fold F1\n" + str(k_fold_score) + "\n")
# roc auc
k_fold_score = cross_val_score(dt,X_train,y_train, cv=kf,scoring='roc_auc')
print("K Fold ROC AUC\n" + str(k_fold_score) + "\n")